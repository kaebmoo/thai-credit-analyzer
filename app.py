"""
Credit Card Analyzer
‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á
"""

import streamlit as st
import sqlite3
import json
import io
import os
from datetime import datetime
from pathlib import Path

from google import genai
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image
import fitz  # PyMuPDF
from dotenv import load_dotenv
import hashlib

# ‚îÄ‚îÄ‚îÄ Config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Database location: default = project folder, set USE_HOME_DIR=true to use home directory
if os.environ.get("USE_HOME_DIR", "").lower() == "true":
    DB_DIR = Path.home() / ".credit_analyzer"
else:
    DB_DIR = Path(__file__).parent / "data"

DB_DIR.mkdir(exist_ok=True)
DB_PATH   = DB_DIR / "data.db"
CONFIG_PATH = DB_DIR / "config.json"

# .env ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å load ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
# Priority: session_state (UI) > .env > config.json
_APP_DIR = Path(__file__).parent
load_dotenv(_APP_DIR / ".env", override=False)

CATEGORIES = [
    "‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô",
    "Subscription/‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•",
    "‡∏£‡πâ‡∏≤‡∏ô‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏ã‡∏∑‡πâ‡∏≠",
    "‡∏ä‡πâ‡∏≠‡∏õ‡∏õ‡∏¥‡πâ‡∏á‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå",
    "‡∏ó‡∏≤‡∏á‡∏î‡πà‡∏ß‡∏ô/‡∏Ç‡∏ô‡∏™‡πà‡∏á",
    "‡∏≠‡∏≤‡∏´‡∏≤‡∏£/‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏∑‡πà‡∏°",
    "‡∏ã‡∏∏‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏°‡∏≤‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ï",
    "‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå/‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï",
    "‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á",
    "‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå",
    "‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û",
    "‡∏ä‡πâ‡∏≠‡∏õ‡∏õ‡∏¥‡πâ‡∏á",
    "‡∏≠‡∏∑‡πà‡∏ô‡πÜ",
]

SUBCATEGORIES = {
    "‡∏≠‡∏≤‡∏´‡∏≤‡∏£/‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏∑‡πà‡∏°": ["‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£", "‡∏Ñ‡∏≤‡πÄ‡∏ü‡πà", "Food Delivery", "‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≠‡∏á‡∏Å‡∏¥‡∏ô"],
    "‡∏ä‡πâ‡∏≠‡∏õ‡∏õ‡∏¥‡πâ‡∏á‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå": ["Shopee", "Lazada", "Amazon", "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"],
    "‡∏ó‡∏≤‡∏á‡∏î‡πà‡∏ß‡∏ô/‡∏Ç‡∏ô‡∏™‡πà‡∏á": ["‡∏ó‡∏≤‡∏á‡∏î‡πà‡∏ß‡∏ô", "‡πÅ‡∏ó‡πá‡∏Å‡∏ã‡∏µ‡πà/Grab", "‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤", "‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô"],
    "‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á": ["‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°", "‡∏ï‡∏±‡πã‡∏ß‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ö‡∏¥‡∏ô", "‡∏ó‡∏±‡∏ß‡∏£‡πå", "‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß", "‡∏£‡∏ñ‡πÄ‡∏ä‡πà‡∏≤"],
    "Subscription/‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•": ["Netflix/Streaming", "Spotify/Music", "‡πÄ‡∏Å‡∏°", "Cloud/Software"],
    "‡∏£‡πâ‡∏≤‡∏ô‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏ã‡∏∑‡πâ‡∏≠": ["CJ", "7-11", "Family Mart", "Lotus Go", "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"],
    "‡∏ã‡∏∏‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏°‡∏≤‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ï": ["Lotus", "Big C", "Tops", "Villa Market", "Makro"],
    "‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå/‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï": ["AIS", "True", "DTAC", "NT", "3BB/Fiber"],
    "‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô": ["‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå", "‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û", "‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï", "‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏™‡∏¥‡∏ô"],
    "‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå": ["‡∏¢‡∏≤‡∏á/‡πÄ‡∏ö‡∏£‡∏Å", "‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á", "‡πÅ‡∏ö‡∏ï‡πÄ‡∏ï‡∏≠‡∏£‡∏µ‡πà", "‡∏ã‡πà‡∏≠‡∏°‡∏ö‡∏≥‡∏£‡∏∏‡∏á", "‡∏•‡πâ‡∏≤‡∏á‡∏£‡∏ñ"],
    "‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û": ["‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•", "‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å", "‡∏£‡πâ‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏¢‡∏≤", "‡∏ó‡∏±‡∏ô‡∏ï‡∏Å‡∏£‡∏£‡∏°", "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û"],
    "‡∏ä‡πâ‡∏≠‡∏õ‡∏õ‡∏¥‡πâ‡∏á": ["‡∏Å‡∏µ‡∏¨‡∏≤", "‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤", "‡∏Ç‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ö‡πâ‡∏≤‡∏ô", "‡∏´‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏û‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤", "‡∏≠‡∏¥‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏£‡∏≠‡∏ô‡∏¥‡∏Å‡∏™‡πå"],
}

# ‚îÄ‚îÄ‚îÄ Database ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def get_db():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn


def init_db():
    conn = get_db()
    conn.executescript("""
        CREATE TABLE IF NOT EXISTS statements (
            id          INTEGER PRIMARY KEY AUTOINCREMENT,
            filename    TEXT,
            bank        TEXT,
            period      TEXT,
            imported_at TEXT,
            tx_count    INTEGER,
            cutoff_day  INTEGER,
            file_hash   TEXT
        );

        CREATE TABLE IF NOT EXISTS transactions (
            id            INTEGER PRIMARY KEY AUTOINCREMENT,
            statement_id  INTEGER,
            trans_date    TEXT,
            posting_date  TEXT,
            description   TEXT,
            amount        REAL,
            category      TEXT,
            subcategory   TEXT,
            bank          TEXT,
            FOREIGN KEY (statement_id) REFERENCES statements(id)
        );
    """)

    # Migration: add missing columns for existing databases (won't run on fresh install)
    stmt_cols = {row["name"] for row in conn.execute("PRAGMA table_info(statements)").fetchall()}
    tx_cols   = {row["name"] for row in conn.execute("PRAGMA table_info(transactions)").fetchall()}
    if "cutoff_day" not in stmt_cols:
        conn.execute("ALTER TABLE statements ADD COLUMN cutoff_day INTEGER")
    if "file_hash" not in stmt_cols:
        conn.execute("ALTER TABLE statements ADD COLUMN file_hash TEXT")
    if "subcategory" not in tx_cols:
        conn.execute("ALTER TABLE transactions ADD COLUMN subcategory TEXT")

    conn.commit()
    conn.close()


def save_transactions(bank: str, filenames: list, transactions: list,
                      cutoff_day: int = None, file_hashes: list = None):
    conn = get_db()
    try:
        dates = [t["trans_date"] for t in transactions if t.get("trans_date")]
        period = max(dates)[:7] if dates else datetime.now().strftime("%Y-%m")

        hash_str = ",".join(file_hashes) if file_hashes else None
        cur = conn.execute(
            "INSERT INTO statements (filename, bank, period, imported_at, tx_count, cutoff_day, file_hash) VALUES (?,?,?,?,?,?,?)",
            (", ".join(filenames), bank, period, datetime.now().isoformat(), len(transactions), cutoff_day, hash_str),
        )
        stmt_id = cur.lastrowid

        for t in transactions:
            conn.execute(
                """INSERT INTO transactions
                   (statement_id, trans_date, posting_date, description, amount, category, subcategory, bank)
                   VALUES (?,?,?,?,?,?,?,?)""",
                (
                    stmt_id,
                    t.get("trans_date", ""),
                    t.get("posting_date", ""),
                    t.get("description", ""),
                    float(t.get("amount", 0)),
                    t.get("category", "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"),
                    t.get("subcategory"),
                    bank,
                ),
            )
        conn.commit()
    finally:
        conn.close()


def delete_statement(stmt_id: int):
    conn = get_db()
    try:
        conn.execute("DELETE FROM transactions WHERE statement_id=?", (stmt_id,))
        conn.execute("DELETE FROM statements WHERE id=?", (stmt_id,))
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        conn.close()


def load_transactions(period: str = "all") -> pd.DataFrame:
    conn = get_db()
    df = pd.read_sql(
        """SELECT t.id, t.trans_date, t.description, t.amount, t.category, t.subcategory, t.bank,
                  s.period, s.id as statement_id, s.cutoff_day
           FROM transactions t
           JOIN statements s ON t.statement_id = s.id
           ORDER BY t.trans_date DESC""",
        conn,
    )
    conn.close()
    if df.empty:
        return df
    df["trans_date"] = pd.to_datetime(df["trans_date"], errors="coerce")

    # Filter by period
    if period == "current_month":
        now = pd.Timestamp.now()
        df = df[(df["trans_date"].dt.year == now.year) &
                (df["trans_date"].dt.month == now.month)]
    elif period == "last_month":
        last_month = pd.Timestamp.now() - pd.DateOffset(months=1)
        df = df[(df["trans_date"].dt.year == last_month.year) &
                (df["trans_date"].dt.month == last_month.month)]
    elif period in ["3_months", "6_months"]:
        # Get all unique months in data, sorted newest first
        all_months = sorted(df["trans_date"].dt.to_period("M").dropna().unique(), reverse=True)
        n = 3 if period == "3_months" else 6
        recent_months = all_months[:n]
        df = df[df["trans_date"].dt.to_period("M").isin(recent_months)]
    # else: period == "all" -> no filter

    return df


def load_statements() -> pd.DataFrame:
    conn = get_db()
    df = pd.read_sql("SELECT * FROM statements ORDER BY imported_at DESC", conn)
    conn.close()
    return df


def get_previous_banks() -> list[str]:
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£/‡∏ö‡∏±‡∏ï‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô (‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô)"""
    conn = get_db()
    rows = conn.execute(
        "SELECT bank, MAX(imported_at) as last_import "
        "FROM statements WHERE bank IS NOT NULL AND bank != '' "
        "GROUP BY bank ORDER BY last_import DESC"
    ).fetchall()
    conn.close()
    return [row["bank"].strip() for row in rows if row["bank"].strip()]


def compute_file_hash(raw: bytes) -> str:
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì SHA-256 hash ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ã‡πâ‡∏≥"""
    return hashlib.sha256(raw).hexdigest()


def find_duplicate_statement(file_hash: str) -> dict | None:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏Ñ‡∏¢‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡πÇ‡∏î‡∏¢‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö SHA-256 hash
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• statement ‡πÄ‡∏î‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡∏û‡∏ö ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô‡∏Ñ‡∏∑‡∏ô None"""
    if not file_hash:
        return None
    conn = get_db()
    # file_hash ‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡πá‡∏ö‡∏´‡∏•‡∏≤‡∏¢ hash ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ "," (‡∏Å‡∏£‡∏ì‡∏µ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô)
    rows = conn.execute(
        "SELECT id, filename, bank, period, imported_at, file_hash FROM statements WHERE file_hash IS NOT NULL"
    ).fetchall()
    conn.close()
    for row in rows:
        stored = [h.strip() for h in (row["file_hash"] or "").split(",")]
        if file_hash in stored:
            return dict(row)
    return None


def find_similar_statement(bank: str, period: str, total_amount: float,
                           tolerance: float = 0.05) -> list[dict]:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö statement ‡∏ó‡∏µ‡πà period ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á (¬±tolerance)
    ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö exact (period+bank) ‡πÅ‡∏•‡∏∞ soft (period ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
    ‡∏Ñ‡∏∑‡∏ô list ‡∏Ç‡∏≠‡∏á statement ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥"""
    conn = get_db()
    # ‡∏î‡∏∂‡∏á statement ‡∏ó‡∏∏‡∏Å‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà period ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô (‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î bank ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà OCR ‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô)
    rows = conn.execute(
        """
        SELECT s.id, s.filename, s.bank, s.period, s.imported_at,
               COALESCE(SUM(CASE WHEN t.amount > 0 THEN t.amount ELSE 0 END), 0) as total_amount
        FROM statements s
        LEFT JOIN transactions t ON t.statement_id = s.id
        WHERE s.period = ?
        GROUP BY s.id
        """,
        (period,),
    ).fetchall()
    conn.close()

    results = []
    for row in rows:
        existing_total = row["total_amount"]
        if existing_total == 0 and total_amount == 0:
            results.append({**dict(row), "diff_ratio": 0.0, "bank_match": row["bank"] == bank})
            continue
        if existing_total == 0:
            continue
        diff_ratio = abs(total_amount - existing_total) / max(abs(existing_total), 1)
        if diff_ratio <= tolerance:
            results.append({**dict(row), "diff_ratio": diff_ratio, "bank_match": row["bank"] == bank})
    return results


def find_overlapping_transactions(transactions: list[dict]) -> dict:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô transactions ‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô DB ‡∏°‡∏≤‡∏Å‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô
    ‡πÉ‡∏ä‡πâ 2 ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ô:
      - exact: trans_date + description + amount (¬±1) ‚Äî ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡∏û‡∏•‡∏≤‡∏î‡∏ñ‡πâ‡∏≤ OCR ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô
      - soft : trans_date + amount (¬±1) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‚Äî ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πâ description ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô
    ‡∏Ñ‡∏∑‡∏ô dict: {exact_count, soft_count, overlap_ratio, total}"""
    if not transactions:
        return {"exact_count": 0, "soft_count": 0, "overlap_ratio": 0.0, "total": 0}

    conn = get_db()
    exact_count = 0
    soft_count = 0
    for t in transactions:
        date_str = t.get("trans_date", "")
        desc = t.get("description", "")
        amount = float(t.get("amount", 0))
        if amount <= 0:
            continue  # ‡∏Ç‡πâ‡∏≤‡∏° cashback/negative

        # exact match
        exact = conn.execute(
            """
            SELECT id FROM transactions
            WHERE trans_date = ? AND description = ?
              AND ABS(amount - ?) < 1.0
            LIMIT 1
            """,
            (date_str, desc, amount),
        ).fetchone()
        if exact:
            exact_count += 1

        # soft match (date + amount ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)
        soft = conn.execute(
            """
            SELECT id FROM transactions
            WHERE trans_date = ? AND ABS(amount - ?) < 1.0
            LIMIT 1
            """,
            (date_str, amount),
        ).fetchone()
        if soft:
            soft_count += 1

    conn.close()

    # ‡∏ô‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ amount > 0 ‡πÄ‡∏õ‡πá‡∏ô base
    positive_total = sum(1 for t in transactions if float(t.get("amount", 0)) > 0)
    if positive_total == 0:
        return {"exact_count": 0, "soft_count": 0, "overlap_ratio": 0.0, "total": len(transactions)}

    # ‡πÉ‡∏ä‡πâ soft_count ‡πÄ‡∏õ‡πá‡∏ô ratio ‡∏´‡∏•‡∏±‡∏Å (‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û)
    ratio = soft_count / positive_total
    return {
        "exact_count": exact_count,
        "soft_count": soft_count,
        "overlap_ratio": ratio,
        "total": len(transactions),
        "positive_total": positive_total,
    }

# ‚îÄ‚îÄ‚îÄ Gemini ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def get_model():
    key = st.session_state.get("api_key", "")
    if not key:
        st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà Gemini API Key ‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ '‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤' ‡∏Å‡πà‡∏≠‡∏ô")
        st.stop()
    return genai.Client(api_key=key)


def extract_from_image(model, image: Image.Image) -> dict:
    prompt = """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡πà‡∏≤‡∏ô statement ‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï

‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏¥‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON object ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ markdown

‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:
{
  "transactions": [
    {
      "trans_date": "2026-01-15",
      "posting_date": "2026-01-16",
      "description": "TMN 7-11 BANGKOK TH",
      "amount": 150.00,
      "is_payment": false
    }
  ],
  "cutoff_day": 20,
  "bank_name": "‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢",
  "card_name": "Visa Platinum"
}

‡∏Å‡∏é:
- ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô YYYY-MM-DD ‡πÄ‡∏™‡∏°‡∏≠
- ‡πÉ‡∏ö‡πÅ‡∏à‡πâ‡∏á‡∏¢‡∏≠‡∏î‡πÑ‡∏ó‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö dd/mm/yy ‡∏´‡∏£‡∏∑‡∏≠ dd/mm/yyyy (‡∏ß‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡πÄ‡∏™‡∏°‡∏≠)
  ‡πÄ‡∏ä‡πà‡∏ô "17/01/26" = ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 17 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô 01 (‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°) ‡∏õ‡∏µ 2026 ‚Üí 2026-01-17
       "05/02/26" = ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 5 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô 02 (‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå) ‡∏õ‡∏µ 2026 ‚Üí 2026-02-05
- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏Ñ‡πà 2 ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏õ‡∏µ (‡πÄ‡∏ä‡πà‡∏ô 26) ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ 2026
- ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏•‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‚Äî ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏£‡∏Å (‡∏Å‡πà‡∏≠‡∏ô /) ‡∏Ñ‡∏∑‡∏≠‡∏ß‡∏±‡∏ô ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
- amount ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏•‡πâ‡∏ß‡∏ô ‡πÑ‡∏°‡πà‡∏°‡∏µ comma
- is_payment = true ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡πÄ‡∏á‡∏¥‡∏ô (Payment, ‡∏¢‡∏≠‡∏î‡∏ä‡∏≥‡∏£‡∏∞, ‡∏¢‡∏≠‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Å‡πá‡∏ö)
- cutoff_day = ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡∏£‡∏≠‡∏ö‡∏ö‡∏¥‡∏• (‡πÄ‡∏ä‡πà‡∏ô 15, 20, 25) ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà null
- bank_name = ‡∏ä‡∏∑‡πà‡∏≠‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ú‡∏π‡πâ‡∏≠‡∏≠‡∏Å‡∏ö‡∏±‡∏ï‡∏£ ‡πÄ‡∏ä‡πà‡∏ô "‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢", "‡πÑ‡∏ó‡∏¢‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå", "‡∏Å‡∏£‡∏∏‡∏á‡πÑ‡∏ó‡∏¢", "‡∏Å‡∏£‡∏∏‡∏á‡∏®‡∏£‡∏µ", "‡∏ó‡∏´‡∏≤‡∏£‡πÑ‡∏ó‡∏¢‡∏ò‡∏ô‡∏ä‡∏≤‡∏ï", "‡∏ã‡∏¥‡∏ï‡∏µ‡πâ‡πÅ‡∏ö‡∏á‡∏Å‡πå" ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà null
- card_name = ‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ö‡∏±‡∏ï‡∏£ ‡πÄ‡∏ä‡πà‡∏ô "Visa Platinum", "World Mastercard", "JCB Precious" ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà null
- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏†‡∏≤‡∏û ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á {"transactions": [], "cutoff_day": null, "bank_name": null, "card_name": null}

‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å ‚Äî ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡πâ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏™‡πà‡∏á {"transactions": [], "cutoff_day": null} ‡∏Å‡∏•‡∏±‡∏ö):
- ‡∏´‡∏ô‡πâ‡∏≤ "‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡πÄ‡∏á‡∏¥‡∏ô" / "Methods of Payment"
- ‡∏´‡∏ô‡πâ‡∏≤ "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢" / "Example of Interest Calculation"
- ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á" / "Example" ‡πÄ‡∏î‡πà‡∏ô‡∏ä‡∏±‡∏î ‡∏ã‡∏∂‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏¥‡∏á
- ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞‡πÄ‡∏á‡∏¥‡∏ô (Pay-in Slip) ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢
- ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏µ‡∏õ‡∏µ ‡∏Ñ.‡∏®. ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏µ‡∏´‡∏•‡∏±‡∏Å (statement) ‡πÄ‡∏Å‡∏¥‡∏ô 2 ‡∏õ‡∏µ ‚Üí ‡∏Ç‡πâ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏ô‡πâ‡∏≤
  (‡πÄ‡∏ä‡πà‡∏ô statement ‡∏õ‡∏µ 2026 ‡πÅ‡∏ï‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏µ‡∏õ‡∏µ 2020, 2021 = ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ ‚Üí ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏¥‡∏á)
"""
    response = model.models.generate_content(
        model="gemini-2.0-flash",
        contents=[prompt, image],
    )
    text = response.text.strip()
    # Strip markdown fences if any
    for fence in ["```json", "```"]:
        if fence in text:
            text = text.split(fence)[1].split("```")[0].strip()
            break
    return json.loads(text)


def get_few_shot_examples(limit_per_cat: int = 3) -> list[dict]:
    """‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á transaction ‡∏à‡∏≤‡∏Å DB ‡∏ó‡∏µ‡πà‡∏°‡∏µ category+subcategory ‡πÅ‡∏•‡πâ‡∏ß
    ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å limit_per_cat ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠ category ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°"""
    conn = get_db()
    rows = conn.execute("""
        SELECT description, category, subcategory
        FROM (
            SELECT description, category, subcategory,
                   ROW_NUMBER() OVER (PARTITION BY category ORDER BY RANDOM()) AS rn
            FROM transactions
            WHERE category IS NOT NULL AND category != '' AND category != '‡∏≠‡∏∑‡πà‡∏ô‡πÜ'
        )
        WHERE rn <= ?
        ORDER BY category
    """, (limit_per_cat,)).fetchall()
    conn.close()
    return [{"description": r["description"], "category": r["category"],
             "subcategory": r["subcategory"]} for r in rows]


def categorize(model, descriptions: list, examples: list[dict] | None = None) -> list:
    cats = ", ".join(CATEGORIES)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á few-shot block ‡∏à‡∏≤‡∏Å examples ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô DB
    few_shot_block = ""
    if examples:
        few_shot_block = "\n‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ö‡∏±‡∏ï‡∏£‡πÉ‡∏ö‡∏ô‡∏µ‡πâ (‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô reference):\n"
        for ex in examples:
            few_shot_block += f'- "{ex["description"]}" ‚Üí {ex["category"]}\n'
        few_shot_block += "\n"

    prompt = f"""‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ

‡∏´‡∏°‡∏ß‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô: {cats}
{few_shot_block}
‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (JSON array):
{json.dumps(descriptions, ensure_ascii=False)}

‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON array ‡∏Ç‡∏≠‡∏á string ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö input
‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ markdown

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á output: ["‡∏£‡πâ‡∏≤‡∏ô‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏ã‡∏∑‡πâ‡∏≠", "Subscription/‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•"]

‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î (‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡∏£‡∏á‡πÜ):
- CJ, 7-11, 7-ELEVEN, TMN 7-11 ‚Üí ‡∏£‡πâ‡∏≤‡∏ô‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏ã‡∏∑‡πâ‡∏≠
- Netflix, Spotify, Google, Apple, Anthropic, Claude, Microsoft, LINE, Adobe, ChatGPT, DYN, Moonshot ‚Üí Subscription/‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•
- Shopee, Lazada, Temu, 2C2P, LAZADA ‚Üí ‡∏ä‡πâ‡∏≠‡∏õ‡∏õ‡∏¥‡πâ‡∏á‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå
- EASYBILLS, Easy Pass, Expressway, BEM, GRABTAXI, GRAB TAXI ‚Üí ‡∏ó‡∏≤‡∏á‡∏î‡πà‡∏ß‡∏ô/‡∏Ç‡∏ô‡∏™‡πà‡∏á
- WWW.GRAB.COM, GRABFOOD, GRAB FOOD, LINE MAN, LPTH*PF_LM, Restaurant, Food, Bistro, Bar, Cafe, Starbucks, Fast Food, ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‚Üí ‡∏≠‡∏≤‡∏´‡∏≤‡∏£/‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏∑‡πà‡∏°
- Hospital, Clinic, HOSPITAL, CLINIC, DENTAL, Pharmacy, MED, ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•, ‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å, ‡∏£‡πâ‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏¢‡∏≤ ‚Üí ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û
- TOPS, Lotus, Big C, Makro, Gourmet, Supermarket ‚Üí ‡∏ã‡∏∏‡∏õ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏°‡∏≤‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ï
- AIS, TRUE, DTAC, TOT, Internet, Telephone ‚Üí ‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå/‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï
- Airline, Hotel, Travel, Agoda, Booking, TRAVEL, ASCENDTRAVEL ‚Üí ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á
- AIA, Insurance, IPAYAGT, QR-AIA, ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‚Üí ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô
- B-QUIK, Firestone, Bridgestone, Goodyear, Autocare, ‡∏ä‡πà‡∏≤‡∏á‡∏¢‡∏ô‡∏ï‡πå, ‡∏ã‡πà‡∏≠‡∏°‡∏£‡∏ñ, ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏¢‡∏≤‡∏á, ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ñ‡πà‡∏≤‡∏¢‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô ‚Üí ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå
- DECATHLON, CENTRAL, ROBINSON, THE MALL, IKEA, INDEX, POWER BUY, BANANA IT, ‡∏´‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏û‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤, ‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤ offline ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‚Üí ‡∏ä‡πâ‡∏≠‡∏õ‡∏õ‡∏¥‡πâ‡∏á
"""
    response = model.models.generate_content(
        model="gemini-2.0-flash",
        contents=prompt,
    )
    text = response.text.strip()
    for fence in ["```json", "```"]:
        if fence in text:
            text = text.split(fence)[1].split("```")[0].strip()
            break
    return json.loads(text)


def subcategorize(model, descriptions: list, categories: list,
                  examples: list[dict] | None = None) -> list:
    """‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏¢‡πà‡∏≠‡∏¢‡∏ï‡∏≤‡∏° category ‡∏´‡∏•‡∏±‡∏Å - batch ‡πÇ‡∏î‡∏¢‡∏Å‡∏•‡∏∏‡πà‡∏° category"""
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á result array ‡πÄ‡∏ï‡πá‡∏°‡∏î‡πâ‡∏ß‡∏¢ None ‡∏Å‡πà‡∏≠‡∏ô
    results = [None] * len(descriptions)

    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° category
    from collections import defaultdict
    groups = defaultdict(list)
    for i, (desc, cat) in enumerate(zip(descriptions, categories)):
        if cat in SUBCATEGORIES:
            groups[cat].append((i, desc))

    # index examples ‡∏ï‡∏≤‡∏° category ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏£‡πá‡∏ß
    examples_by_cat: dict[str, list] = defaultdict(list)
    for ex in (examples or []):
        if ex.get("subcategory") and ex["category"] in SUBCATEGORIES:
            examples_by_cat[ex["category"]].append(ex)

    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞ category ‡πÄ‡∏õ‡πá‡∏ô batch
    for cat, items in groups.items():
        if not items:
            continue

        indices = [i for i, _ in items]
        descs = [d for _, d in items]
        subcats = ", ".join(SUBCATEGORIES[cat])

        # few-shot block ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ category ‡∏ô‡∏µ‡πâ
        few_shot_block = ""
        if examples_by_cat[cat]:
            few_shot_block = "\n‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥:\n"
            for ex in examples_by_cat[cat]:
                few_shot_block += f'- "{ex["description"]}" ‚Üí {ex["subcategory"]}\n'
            few_shot_block += "\n"

        prompt = f"""‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ

‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å: {cat}
‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏¢‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô: {subcats}
{few_shot_block}
‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (JSON array):
{json.dumps(descs, ensure_ascii=False)}

‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON array ‡∏Ç‡∏≠‡∏á string ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö input
‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà null
‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ markdown

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á output: ["7-11", "‡∏Ñ‡∏≤‡πÄ‡∏ü‡πà", "Food Delivery", null]
"""
        try:
            response = model.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt,
            )
            text = response.text.strip()
            for fence in ["```json", "```"]:
                if fence in text:
                    text = text.split(fence)[1].split("```")[0].strip()
                    break
            subcats_result = json.loads(text)

            # ‡πÉ‡∏™‡πà‡∏Å‡∏•‡∏±‡∏ö‡πÉ‡∏ô results array
            for idx, subcat in zip(indices, subcats_result):
                if subcat and subcat in SUBCATEGORIES[cat]:
                    results[idx] = subcat
        except Exception as e:
            st.warning(f"‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏¢‡πà‡∏≠‡∏¢‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {cat}: {e}")

    return results


def open_pdf(raw: bytes, password: str = "") -> fitz.Document:
    """‡πÄ‡∏õ‡∏¥‡∏î PDF ‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô"""
    doc = fitz.open(stream=raw, filetype="pdf")
    if doc.needs_pass:
        if not password:
            raise ValueError("PDF_NEEDS_PASSWORD")
        ok = doc.authenticate(password)
        if not ok:
            raise ValueError("PDF_WRONG_PASSWORD")
    return doc


def pdf_to_images(raw: bytes, password: str = "") -> list:
    """‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏≠‡∏á PDF ‡πÄ‡∏õ‡πá‡∏ô PIL Image"""
    doc = open_pdf(raw, password)
    images = []
    for page in doc:
        pix = page.get_pixmap(dpi=150)
        img = Image.open(io.BytesIO(pix.tobytes("png")))
        images.append(img)
    return images


def process_uploaded_file(raw: bytes, filename: str, model, password: str = "") -> tuple:
    from collections import Counter
    name = filename.lower()

    if name.endswith(".pdf"):
        images = pdf_to_images(raw, password)
    else:
        # JPG, JPEG, PNG ‚Äî ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô
        images = [Image.open(io.BytesIO(raw))]

    all_txns = []
    cutoff_days = []  # ‡πÄ‡∏Å‡πá‡∏ö cutoff_day ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤
    bank_names = []   # ‡πÄ‡∏Å‡πá‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤
    card_names = []   # ‡πÄ‡∏Å‡πá‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ï‡∏£‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤
    for img in images:
        try:
            result = extract_from_image(model, img)
            all_txns.extend(result.get("transactions", []))
            if result.get("cutoff_day"):
                cutoff_days.append(result["cutoff_day"])
            if result.get("bank_name"):
                bank_names.append(result["bank_name"])
            if result.get("card_name"):
                card_names.append(result["card_name"])
        except Exception as e:
            st.warning(f"‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å cutoff_day ‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    cutoff_day = None
    if cutoff_days:
        cutoff_day = Counter(cutoff_days).most_common(1)[0][0]

    # Remove payment rows
    expenses = [t for t in all_txns if not t.get("is_payment", False)]

    # ‡∏Å‡∏£‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏£‡∏¥‡∏á (‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å "‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á" ‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏∏‡∏î‡∏°‡∏≤)
    # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 3 ‡∏õ‡∏µ‡∏à‡∏≤‡∏Å‡∏õ‡∏µ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
    current_year = datetime.now().year

    def _is_recent_year(date_str: str) -> bool:
        if not date_str:
            return True
        try:
            y = int(date_str[:4])
            return (current_year - y) <= 3
        except Exception:
            return True  # ‡∏ñ‡πâ‡∏≤ parse ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô

    before_filter = len(expenses)
    expenses = [t for t in expenses if _is_recent_year(t.get("trans_date", ""))]
    filtered_out = before_filter - len(expenses)
    if filtered_out > 0:
        st.info(f"‚ÑπÔ∏è ‡∏Å‡∏£‡∏≠‡∏á {filtered_out} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô 3 ‡∏õ‡∏µ‡∏≠‡∏≠‡∏Å (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£)")

    # ‡πÇ‡∏´‡∏•‡∏î few-shot examples ‡∏à‡∏≤‡∏Å DB (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πá‡πÑ‡∏î‡πâ [] ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤ ‚Äî ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏õ‡∏Å‡∏ï‡∏¥)
    examples = get_few_shot_examples(limit_per_cat=3)

    # Categorize
    if expenses:
        descs = [t["description"] for t in expenses]
        try:
            cats = categorize(model, descs, examples=examples)
            for t, c in zip(expenses, cats):
                t["category"] = c if c in CATEGORIES else "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"
        except Exception as e:
            st.warning(f"‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
            for t in expenses:
                t["category"] = "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"

        # Subcategorize
        try:
            categories = [t["category"] for t in expenses]
            subcats = subcategorize(model, descs, categories, examples=examples)
            for t, sc in zip(expenses, subcats):
                t["subcategory"] = sc
        except Exception as e:
            st.warning(f"‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏¢‡πà‡∏≠‡∏¢‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
            for t in expenses:
                t["subcategory"] = None

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á suggested_bank ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£/‡∏ö‡∏±‡∏ï‡∏£‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å statement
    suggested_bank = None
    if bank_names or card_names:
        bank_count = Counter(b for b in bank_names if b)
        card_count = Counter(c for c in card_names if c)
        top_bank = bank_count.most_common(1)[0][0] if bank_count else ""
        top_card = card_count.most_common(1)[0][0] if card_count else ""
        if top_bank and top_card:
            suggested_bank = f"{top_bank} {top_card}"
        else:
            suggested_bank = top_bank or top_card or None

    return expenses, cutoff_day, suggested_bank

# ‚îÄ‚îÄ‚îÄ Pages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def page_import():
    st.header("‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Statement")

    # ‚îÄ‚îÄ ‡πÅ‡∏™‡∏î‡∏á banner ‡πÄ‡∏°‡∏∑‡πà‡∏≠ save ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡∏Ñ‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ 1 render ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡πâ‡∏≤‡∏á‡∏ó‡∏¥‡πâ‡∏á) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if st.session_state.get("_import_success"):
        msg = st.session_state.pop("_import_success")
        st.success(msg)
        st.balloons()

    # ‚îÄ‚îÄ Auto-fill ‡∏ä‡∏∑‡πà‡∏≠‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏à‡∏≤‡∏Å statement (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏£‡∏≠‡∏Å) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if st.session_state.get("_detected_bank"):
        if not st.session_state.get("_bank_input", "").strip():
            st.session_state["_bank_input"] = st.session_state["_detected_bank"]
        del st.session_state["_detected_bank"]

    # ‚îÄ‚îÄ Previous bank quick-select ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    prev_banks = get_previous_banks()
    if prev_banks:
        st.caption("üí° ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤:")
        btn_cols = st.columns(min(len(prev_banks), 5))
        for i, b in enumerate(prev_banks[:5]):
            if btn_cols[i].button(b, key=f"_prev_bank_{i}", use_container_width=True):
                st.session_state["_bank_input"] = b
                st.rerun()

    bank = st.text_input(
        "‡∏ä‡∏∑‡πà‡∏≠‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£ / ‡∏ö‡∏±‡∏ï‡∏£",
        placeholder="‡πÄ‡∏ä‡πà‡∏ô KTB Visa, SCB Platinum, KBANK",
        help="‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡πÉ‡∏ô‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á ‚Äî ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô statement",
        key="_bank_input",
    )

    # key ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà save ‚Üí ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö file_uploader reset ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
    upload_key = f"uploader_{st.session_state.get('_upload_rev', 0)}"
    uploaded = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Statement (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö PDF, JPG, JPEG, PNG ‚Äî ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ)",
        type=["pdf", "jpg", "jpeg", "png"],
        accept_multiple_files=True,
        key=upload_key,
    )

    # ‚îÄ‚îÄ PDF Password Section ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    has_pdf = uploaded and any(f.name.lower().endswith(".pdf") for f in uploaded)
    pdf_password = ""
    if has_pdf:
        with st.expander("PDF ‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?", expanded=False):
            st.markdown("""
            ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡πà‡∏á‡∏•‡πá‡∏≠‡∏Å PDF ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß ‡πÄ‡∏ä‡πà‡∏ô:
            - **KTB / SCB / KBANK** ‚Äî ‡∏ß‡∏±‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏µ‡πÄ‡∏Å‡∏¥‡∏î ‡πÄ‡∏ä‡πà‡∏ô `01Jan1990`
            - **TTB** ‚Äî ‡πÄ‡∏•‡∏Ç 4 ‡∏ï‡∏±‡∏ß‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏±‡∏ï‡∏£ ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î ‡πÄ‡∏ä‡πà‡∏ô `0101`
            - ‡∏ö‡∏≤‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏Ç‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô

            ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡πÄ‡∏õ‡∏¥‡∏î PDF ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å
            """)
            use_password = st.checkbox("PDF ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô")
            if use_password:
                pdf_password = st.text_input(
                    "‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô PDF",
                    type="password",
                    placeholder="‡πÄ‡∏ä‡πà‡∏ô 01Jan1990",
                    help="‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏õ‡∏¥‡∏î PDF ‚Äî ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å",
                )

    if uploaded:
        if st.button("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", type="primary", use_container_width=True):
            model = get_model()
            all_txns = []
            filenames = []
            file_hashes = []
            errors = []
            cutoff_days = []
            suggested_banks = []
            progress = st.progress(0, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå...")

            for i, f in enumerate(uploaded):
                with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô: {f.name}"):
                    try:
                        raw = f.read()
                        file_hash = compute_file_hash(raw)

                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ã‡πâ‡∏≥‡∏î‡πâ‡∏ß‡∏¢ SHA-256 hash
                        dup = find_duplicate_statement(file_hash)
                        if dup:
                            errors.append(
                                f"**{f.name}** ‚Äî ‚ö†Ô∏è ‡πÄ‡∏Ñ‡∏¢‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß "
                                f"(‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£: {dup['bank']}, ‡∏á‡∏ß‡∏î: {dup['period']}, "
                                f"‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠: {dup['imported_at'][:10]}) ‚Äî "
                                "‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ '‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤' ‡∏Å‡πà‡∏≠‡∏ô"
                            )
                        else:
                            password = pdf_password if f.name.lower().endswith(".pdf") else ""
                            txns, cutoff_day, suggested_bank = process_uploaded_file(raw, f.name, model, password)
                            for t in txns:
                                t["bank"] = bank
                            all_txns.extend(txns)
                            filenames.append(f.name)
                            file_hashes.append(file_hash)
                            if cutoff_day:
                                cutoff_days.append(cutoff_day)
                            if suggested_bank:
                                suggested_banks.append(suggested_bank)
                    except ValueError as e:
                        if "PDF_NEEDS_PASSWORD" in str(e):
                            errors.append(f"**{f.name}** ‚Äî PDF ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏õ‡∏¥‡∏î 'PDF ‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô' ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏™‡πà‡∏£‡∏´‡∏±‡∏™")
                        elif "PDF_WRONG_PASSWORD" in str(e):
                            errors.append(f"**{f.name}** ‚Äî ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
                        else:
                            errors.append(f"**{f.name}** ‚Äî {e}")
                    except Exception as e:
                        errors.append(f"**{f.name}** ‚Äî ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
                progress.progress((i + 1) / len(uploaded), text=f"‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß {i+1}/{len(uploaded)} ‡πÑ‡∏ü‡∏•‡πå")

            for err in errors:
                st.error(err)

            # ‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‚Üí auto-suggest ‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ
            if suggested_banks and not st.session_state.get("_bank_input", "").strip():
                from collections import Counter as _Counter
                best_bank = _Counter(suggested_banks).most_common(1)[0][0]
                st.session_state["_detected_bank"] = best_bank

            if all_txns:
                # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å cutoff_day ‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                final_cutoff = None
                if cutoff_days:
                    from collections import Counter
                    final_cutoff = Counter(cutoff_days).most_common(1)[0][0]

                st.session_state["pending"] = all_txns
                st.session_state["pending_bank"] = bank
                st.session_state["pending_files"] = filenames
                st.session_state["pending_cutoff_day"] = final_cutoff
                st.session_state["pending_file_hashes"] = file_hashes

                success_msg = f"‡∏û‡∏ö {len(all_txns)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"
                success_msg += " ‚Äî ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å"
                st.success(success_msg)
                st.rerun()
            elif not errors:
                st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")

    # ‚îÄ‚îÄ Review pending ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if st.session_state.get("pending"):
        txns = st.session_state["pending"]
        df_pending = pd.DataFrame(txns)[["trans_date", "description", "amount", "category", "subcategory"]]

        st.subheader("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏î‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å)")
        edited = st.data_editor(
            df_pending,
            column_config={
                "trans_date":   st.column_config.TextColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏±‡∏ï‡∏£"),
                "description":  st.column_config.TextColumn("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", width="large"),
                "amount":       st.column_config.NumberColumn("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô (‡∏ö‡∏≤‡∏ó)", format="%.2f"),
                "category":     st.column_config.SelectboxColumn("‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà", options=CATEGORIES),
                "subcategory":  st.column_config.TextColumn("‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏¢‡πà‡∏≠‡∏¢", help="‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ"),
            },
            use_container_width=True,
            num_rows="dynamic",
            key="editor",
        )

        total = edited["amount"].sum()
        st.metric("‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", f"{total:,.2f} ‡∏ö‡∏≤‡∏ó")

        def _do_save(bank: str, final_rows: list):
            """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏•‡πâ‡∏≤‡∏á session state ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"""
            save_transactions(
                bank,
                st.session_state["pending_files"],
                final_rows,
                st.session_state.get("pending_cutoff_day"),
                st.session_state.get("pending_file_hashes"),
            )
            n = len(final_rows)
            for key in ["pending", "pending_bank", "pending_files",
                        "pending_cutoff_day", "pending_file_hashes",
                        "_dup_warnings", "_dup_pending_final", "_dup_pending_bank"]:
                st.session_state.pop(key, None)
            st.session_state["_import_success"] = (
                f"‚úÖ ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å {n} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ({bank}) ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß"
            )
            st.session_state["_upload_rev"] = st.session_state.get("_upload_rev", 0) + 1
            st.rerun()

        # ‚îÄ‚îÄ ‡πÅ‡∏™‡∏î‡∏á duplicate warning + ‡∏õ‡∏∏‡πà‡∏°‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if st.session_state.get("_dup_warnings"):
            warnings = st.session_state["_dup_warnings"]
            st.warning("‚ö†Ô∏è **‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß** ‚Äî ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
            with st.expander("üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥", expanded=True):
                for w in warnings:
                    st.markdown(w)
            confirm = st.checkbox("‡∏â‡∏±‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ã‡πâ‡∏≥ (‡∏°‡∏µ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏°)")
            col_force, col_cancel_dup = st.columns(2)
            with col_force:
                if st.button("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ã‡πâ‡∏≥", type="primary",
                             disabled=not confirm, use_container_width=True):
                    _do_save(
                        st.session_state["_dup_pending_bank"],
                        st.session_state["_dup_pending_final"],
                    )
            with col_cancel_dup:
                if st.button("‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å / ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", use_container_width=True):
                    for key in ["_dup_warnings", "_dup_pending_final", "_dup_pending_bank"]:
                        st.session_state.pop(key, None)
                    st.rerun()
        else:
            c1, c2 = st.columns(2)
            with c1:
                if st.button("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å", type="primary", use_container_width=True):
                    all_rows = edited.to_dict("records")

                    current_bank = st.session_state.get("_bank_input", "").strip()
                    if not current_bank:
                        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£ / ‡∏ö‡∏±‡∏ï‡∏£ ‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
                        st.stop()

                    # ‡∏Å‡∏£‡∏≠‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å
                    final = [
                        row for row in all_rows
                        if str(row.get("description") or "").strip()
                        and row.get("amount") is not None
                        and not (isinstance(row.get("amount"), float) and pd.isna(row["amount"]))
                    ]

                    if not final:
                        st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á")
                    else:
                        # Merge back posting_date from original
                        orig_map = {t["description"]: t for t in txns}
                        for row in final:
                            orig = orig_map.get(row["description"], {})
                            row["posting_date"] = orig.get("posting_date", "")

                        # ‚îÄ‚îÄ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ã‡πâ‡∏≥ 2 ‡∏£‡∏∞‡∏î‡∏±‡∏ö ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                        total_amount = sum(r["amount"] for r in final
                                          if (r.get("amount") or 0) > 0)
                        dates = [r["trans_date"] for r in final if r.get("trans_date")]
                        est_period = max(dates)[:7] if dates else ""

                        dup_warnings = []

                        # Level 1: period + amount-sum (¬±5%) ‚Äî ‡πÑ‡∏°‡πà filter ‡∏î‡πâ‡∏ß‡∏¢ bank
                        if est_period:
                            similar = find_similar_statement(current_bank, est_period, total_amount)
                            for s in similar:
                                diff_pct = s.get("diff_ratio", 0) * 100
                                bank_note = "‚úÖ ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô" if s.get("bank_match") else f"‚ùì ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£: **{s['bank']}**"
                                dup_warnings.append(
                                    f"‚ö†Ô∏è **[‡∏£‡∏∞‡∏î‡∏±‡∏ö Statement]** ‡∏û‡∏ö statement ‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô: "
                                    f"‡∏á‡∏ß‡∏î **{s['period']}** {bank_note} "
                                    f"(‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠ {s['imported_at'][:10]}) ‚Äî "
                                    f"‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô **{diff_pct:.1f}%**"
                                )

                        # Level 2: transaction-level overlap (‚â•50% soft match = date+amount)
                        overlap = find_overlapping_transactions(final)
                        pos_total = overlap.get("positive_total", overlap.get("total", 1))
                        if overlap["overlap_ratio"] >= 0.5:
                            exact = overlap.get("exact_count", 0)
                            soft  = overlap.get("soft_count", 0)
                            dup_warnings.append(
                                f"‚ö†Ô∏è **[‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£]** ‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö DB ‡πÅ‡∏•‡πâ‡∏ß: "
                                f"‡∏ï‡∏£‡∏á‡∏ó‡∏±‡πâ‡∏á desc+amount **{exact}/{pos_total}** ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ | "
                                f"‡∏ï‡∏£‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ß‡∏±‡∏ô+amount **{soft}/{pos_total}** ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ "
                                f"(**{overlap['overlap_ratio']*100:.0f}%**)"
                            )


                        if dup_warnings:
                            st.session_state["_dup_warnings"] = dup_warnings
                            st.session_state["_dup_pending_final"] = final
                            st.session_state["_dup_pending_bank"] = current_bank
                            st.rerun()
                        else:
                            _do_save(current_bank, final)

            with c2:
                if st.button("‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å", use_container_width=True):
                    for key in ["pending", "pending_bank", "pending_files"]:
                        st.session_state.pop(key, None)
                    st.rerun()



def page_dashboard():
    st.header("Dashboard")

    period_options = {
        "current_month": "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ",
        "last_month": "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß",
        "3_months": "3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î",
        "6_months": "6 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î",
        "all": "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
    }
    period = st.selectbox(
        "‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤",
        options=list(period_options.keys()),
        format_func=lambda x: period_options[x],
        index=1,  # default = ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß
    )

    period_label = period_options[period]

    # toggle: group by trans_date month vs billing period from statement
    group_mode = st.radio(
        "‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏°",
        ["‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á", "‡∏á‡∏ß‡∏î‡∏ö‡∏¥‡∏•"],
        horizontal=True,
        help=(
            "'‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á' = ‡∏ô‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏π‡∏î‡∏ö‡∏±‡∏ï‡∏£  |  "
            "'‡∏á‡∏ß‡∏î‡∏ö‡∏¥‡∏•' = ‡∏ô‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏á‡∏ß‡∏î‡πÉ‡∏ö‡πÅ‡∏à‡πâ‡∏á‡∏´‡∏ô‡∏µ‡πâ‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£ "
            "(‡πÄ‡∏ä‡πà‡∏ô KBank ‡∏Å.‡∏û. + KTB ‡∏Å.‡∏û. = ‡∏á‡∏ß‡∏î ‡∏Å.‡∏û. ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏ß‡∏±‡∏ô‡∏ï‡∏±‡∏î‡∏£‡∏≠‡∏ö)"
        ),
    )

    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÅ‡∏•‡πâ‡∏ß filter ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    df = load_transactions("all")

    if df.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Äî ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Statement ‡πÉ‡∏ô‡πÄ‡∏°‡∏ô‡∏π '‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Statement' ‡∏Å‡πà‡∏≠‡∏ô")
        return

    if group_mode == "‡∏á‡∏ß‡∏î‡∏ö‡∏¥‡∏•":
        # ‡πÉ‡∏ä‡πâ period ‡∏Ç‡∏≠‡∏á statement ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (YYYY-MM) ‚Äî ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ß‡∏±‡∏ô‡∏ï‡∏±‡∏î‡∏£‡∏≠‡∏ö
        # ‡∏ó‡∏∏‡∏Å statement ‡∏°‡∏µ period ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‚Üí KBank ‡∏Å.‡∏û. + KTB ‡∏Å.‡∏û. = period "2026-02" ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        if period == "current_month":
            target = pd.Timestamp.now().strftime("%Y-%m")
            df = df[df["period"] == target]
        elif period == "last_month":
            target = (pd.Timestamp.now() - pd.DateOffset(months=1)).strftime("%Y-%m")
            df = df[df["period"] == target]
        elif period in ["3_months", "6_months"]:
            n = 3 if period == "3_months" else 6
            all_periods = sorted(df["period"].dropna().unique(), reverse=True)
            recent = all_periods[:n]
            df = df[df["period"].isin(recent)]
        # else "all": no filter

        if df.empty:
            st.warning(f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏á‡∏ß‡∏î‡∏ö‡∏¥‡∏• {period_label}")
            return

        df["month_sort"]  = df["period"]
        df["month_label"] = pd.to_datetime(df["period"] + "-01").dt.strftime("‡∏á‡∏ß‡∏î %b %Y")

    else:
        # ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á: filter ‡πÇ‡∏î‡∏¢ trans_date
        if period == "current_month":
            now = pd.Timestamp.now()
            df = df[(df["trans_date"].dt.year == now.year) &
                    (df["trans_date"].dt.month == now.month)]
        elif period == "last_month":
            lm = pd.Timestamp.now() - pd.DateOffset(months=1)
            df = df[(df["trans_date"].dt.year == lm.year) &
                    (df["trans_date"].dt.month == lm.month)]
        elif period in ["3_months", "6_months"]:
            n = 3 if period == "3_months" else 6
            all_months = sorted(df["trans_date"].dt.to_period("M").dropna().unique(), reverse=True)
            recent_months = all_months[:n]
            df = df[df["trans_date"].dt.to_period("M").isin(recent_months)]

        if df.empty:
            st.warning(f"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á {period_label}")
            return

        df["month_sort"]  = df["trans_date"].dt.strftime("%Y-%m")
        df["month_label"] = df["trans_date"].dt.strftime("%b %Y")

    # sort mapping: month_label ‚Üí month_sort (for ordering)
    label_order = (
        df[["month_sort", "month_label"]]
        .drop_duplicates()
        .sort_values("month_sort")["month_label"]
        .tolist()
    )

    # ‚îÄ‚îÄ KPI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    total = df["amount"].sum()
    num_months = df["month_sort"].nunique()
    avg_monthly = df.groupby("month_sort")["amount"].sum().mean()
    top_cat = df.groupby("category")["amount"].sum().idxmax()

    c1, c2, c3 = st.columns(3)
    c1.metric(f"‡∏£‡∏ß‡∏° ({period_label})", f"{total:,.0f} ‡∏ö‡∏≤‡∏ó")
    if num_months > 1:
        c2.metric(f"‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ({num_months} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)", f"{avg_monthly:,.0f} ‡∏ö‡∏≤‡∏ó")
    else:
        c2.metric("‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", f"{avg_monthly:,.0f} ‡∏ö‡∏≤‡∏ó")
    c3.metric("‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î", top_cat)

    st.divider()

    # ‚îÄ‚îÄ Charts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    c1, c2 = st.columns(2)

    with c1:
        st.subheader("‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sunburst: category > subcategory
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô > 0 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≤‡∏ü Sunburst ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö
        df_chart = df[df["amount"] > 0].copy()
        df_chart["display_path"] = df_chart.apply(
            lambda row: f"{row['category']} > {row['subcategory']}"
                if pd.notna(row['subcategory']) and str(row['subcategory']).strip() != ""
                else row['category'],
            axis=1
        )

        # Group by path ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏° amount
        path_df = df_chart.groupby("display_path")["amount"].sum().reset_index()

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á go.Sunburst nodes ‡πÅ‡∏ö‡∏ö explicit
        # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ category ‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ subcategory ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ (px.sunburst ‡∏ó‡∏≥‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ)
        cat_totals: dict = {}   # cat ‚Üí ‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        cat_subs: dict = {}     # cat ‚Üí {sub ‚Üí amount}

        for _, row in path_df.iterrows():
            parts = row["display_path"].split(" > ", 1)
            cat = parts[0]
            amt = row["amount"]
            cat_totals[cat] = cat_totals.get(cat, 0) + amt
            if len(parts) == 2:
                if cat not in cat_subs:
                    cat_subs[cat] = {}
                cat_subs[cat][parts[1]] = cat_subs[cat].get(parts[1], 0) + amt

        ids, labels, parents, values = [], [], [], []

        # Category nodes (‡∏ä‡∏±‡πâ‡∏ô‡πÅ‡∏£‡∏Å ‚Äî ‡∏£‡∏≤‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î)
        for cat, total in cat_totals.items():
            ids.append(cat)
            labels.append(cat)
            parents.append("")
            values.append(total)

        # Subcategory nodes (‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á)
        for cat, subs in cat_subs.items():
            sub_total = sum(subs.values())
            remainder = cat_totals[cat] - sub_total

            for sub, amt in subs.items():
                ids.append(f"{cat}/{sub}")
                labels.append(sub)
                parents.append(cat)
                values.append(amt)

            # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ subcategory ‚Üí ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô "‡∏≠‡∏∑‡πà‡∏ô‡πÜ" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏Ç‡∏≤‡∏ß
            if remainder > 0.01:
                ids.append(f"{cat}/_other")
                labels.append("‡∏≠‡∏∑‡πà‡∏ô‡πÜ")
                parents.append(cat)
                values.append(remainder)

        fig = go.Figure(go.Sunburst(
            ids=ids,
            labels=labels,
            parents=parents,
            values=values,
            branchvalues="total",
            textinfo="label+value+percent parent",
            texttemplate="%{label}<br>‡∏ø%{value:,.0f}<br>%{percentParent:.1%}",
            insidetextorientation="radial",
            hovertemplate="<b>%{label}</b><br>‡∏ø%{value:,.0f}<br>%{percentParent:.1%}<extra></extra>",
        ))
        fig.update_layout(height=380, margin=dict(t=10, b=10, l=10, r=10))
        st.plotly_chart(fig, use_container_width=True)

    with c2:
        st.subheader("‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
        month_df = df.groupby("month_label")["amount"].sum().reset_index()
        fig = px.bar(month_df, x="month_label", y="amount",
                     text_auto=".0f",
                     category_orders={"month_label": label_order},
                     color_discrete_sequence=["#4C78A8"])
        fig.update_layout(height=380, xaxis_title="", yaxis_title="‡∏ö‡∏≤‡∏ó",
                          xaxis={"type": "category", "categoryorder": "array",
                                 "categoryarray": label_order},
                          margin=dict(t=10, b=10))
        st.plotly_chart(fig, use_container_width=True)

    st.subheader("‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÅ‡∏¢‡∏Å‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
    pivot = df.groupby(["month_label", "category"])["amount"].sum().reset_index()
    fig = px.bar(pivot, x="month_label", y="amount", color="category",
                 barmode="stack",
                 category_orders={"month_label": label_order},
                 color_discrete_sequence=px.colors.qualitative.Set3)
    fig.update_layout(height=400, xaxis_title="", yaxis_title="‡∏ö‡∏≤‡∏ó",
                      xaxis={"type": "category", "categoryorder": "array",
                             "categoryarray": label_order},
                      legend_title="‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà")
    st.plotly_chart(fig, use_container_width=True)

    # ‚îÄ‚îÄ Table ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.subheader("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")

    # Filter by category
    selected_cats = st.multiselect(
        "‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà",
        options=CATEGORIES,
        default=[],
        placeholder="‡∏ó‡∏∏‡∏Å‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà",
    )
    show_df = df.copy()
    if selected_cats:
        show_df = show_df[show_df["category"].isin(selected_cats)]

    # ‚îÄ‚îÄ Summary row ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    filtered_total = show_df["amount"].sum()
    filtered_count = len(show_df)
    label = f"‡∏Å‡∏£‡∏≠‡∏á: {', '.join(selected_cats)}" if selected_cats else "‡∏ó‡∏∏‡∏Å‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà"
    m1, m2 = st.columns(2)
    m1.metric(f"‡∏£‡∏ß‡∏° ({label})", f"‡∏ø{filtered_total:,.2f}")
    m2.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", f"{filtered_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    show_df = show_df.sort_values("trans_date", ascending=False)
    show_df["trans_date"] = show_df["trans_date"].dt.strftime("%d/%m/%Y")

    st.dataframe(
        show_df[["trans_date", "bank", "description", "amount", "category", "subcategory"]],
        column_config={
            "trans_date":   st.column_config.TextColumn("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"),
            "bank":         st.column_config.TextColumn("‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£"),
            "description":  st.column_config.TextColumn("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", width="large"),
            "amount":       st.column_config.NumberColumn("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô", format="‡∏ø%.2f"),
            "category":     st.column_config.TextColumn("‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà"),
            "subcategory":  st.column_config.TextColumn("‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏¢‡πà‡∏≠‡∏¢"),
        },
        use_container_width=True,
        hide_index=True,
    )

    # Download CSV
    csv = show_df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button(
        "‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV",
        data=csv,
        file_name=f"credit_card_{datetime.now().strftime('%Y%m%d')}.csv",
        mime="text/csv",
    )


def page_history():
    st.header("‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤")
    stmts = load_statements()
    if stmts.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        return

    for _, row in stmts.iterrows():
        with st.expander(f"{row['period']} ‚Äî {row['bank']} ({row['tx_count']} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"):
            st.write(f"**‡πÑ‡∏ü‡∏•‡πå:** {row['filename']}")
            st.write(f"**‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠:** {row['imported_at'][:19]}")
            if st.button("‡∏•‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ", key=f"del_{row['id']}", type="secondary"):
                delete_statement(row["id"])
                st.success("‡∏•‡∏ö‡πÅ‡∏•‡πâ‡∏ß")
                st.rerun()


def page_settings():
    st.header("‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")

    st.markdown("""
    **‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ç‡∏≠ Gemini API Key (‡∏ü‡∏£‡∏µ):**
    1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà [aistudio.google.com](https://aistudio.google.com)
    2. Sign in ‡∏î‡πâ‡∏ß‡∏¢ Google account
    3. ‡∏Ñ‡∏•‡∏¥‡∏Å **Get API Key** ‚Üí **Create API key**
    4. Copy key ‡∏°‡∏≤‡πÉ‡∏™‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏™‡πà‡πÉ‡∏ô `.env` ‡πÑ‡∏ü‡∏•‡πå
    """)

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤ key ‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏´‡∏ô
    env_key = os.environ.get("GEMINI_API_KEY", "")
    if env_key:
        st.success("‡∏û‡∏ö GEMINI_API_KEY ‡∏à‡∏≤‡∏Å environment variable (.env) ‚Äî ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏≠‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á")
        source_label = "‡∏°‡∏≤‡∏à‡∏≤‡∏Å: .env / environment variable"
    elif CONFIG_PATH.exists():
        try:
            cfg = json.loads(CONFIG_PATH.read_text())
            if cfg.get("api_key"):
                source_label = "‡∏°‡∏≤‡∏à‡∏≤‡∏Å: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ú‡πà‡∏≤‡∏ô UI (‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô ~/.credit_analyzer/config.json)"
            else:
                source_label = "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤"
        except Exception:
            source_label = "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤"
    else:
        source_label = "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤"

    st.caption(f"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ API Key: {source_label}")

    st.markdown("""
    **2 ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key:**

    **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1 ‚Äî ‡∏ú‡πà‡∏≤‡∏ô UI (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß)**
    ‡∏Å‡∏£‡∏≠‡∏Å key ‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å

    **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2 ‚Äî ‡∏ú‡πà‡∏≤‡∏ô .env file (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏±‡∏î)**
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `.env` ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏™‡πà:
    ```
    GEMINI_API_KEY=AIza...
    ```
    """)

    current_key = st.session_state.get("api_key", "")
    new_key = st.text_input(
        "Gemini API Key (‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ú‡πà‡∏≤‡∏ô UI)",
        value=current_key if not env_key else "",
        type="password",
        placeholder="AIza...",
        disabled=bool(env_key),
        help="‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ .env ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà",
    )

    if not env_key:
        if st.button("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å API Key", type="primary"):
            st.session_state["api_key"] = new_key
            # ‡∏≠‡πà‡∏≤‡∏ô config ‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡πà‡∏≠‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡πÜ
            config = {}
            if CONFIG_PATH.exists():
                try:
                    config = json.loads(CONFIG_PATH.read_text())
                except Exception:
                    pass
            config["api_key"] = new_key
            CONFIG_PATH.write_text(json.dumps(config))
            st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß ‚Äî key ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô config.json ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")

    st.divider()
    st.subheader("‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    conn = get_db()
    n_stmt = conn.execute("SELECT COUNT(*) FROM statements").fetchone()[0]
    n_tx = conn.execute("SELECT COUNT(*) FROM transactions").fetchone()[0]
    conn.close()
    c1, c2 = st.columns(2)
    c1.metric("Statement ‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤", n_stmt)
    c2.metric("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", n_tx)

    st.divider()
    st.caption(f"‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà: `{DB_PATH}`")

# ‚îÄ‚îÄ‚îÄ Main ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def main():
    st.set_page_config(
        page_title="‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    init_db()

    # Load API key ‚Äî priority: session_state (UI) > GEMINI_API_KEY env var > config.json
    if "api_key" not in st.session_state:
        key = os.environ.get("GEMINI_API_KEY", "")
        if not key and CONFIG_PATH.exists():
            try:
                cfg = json.loads(CONFIG_PATH.read_text())
                key = cfg.get("api_key", "")
            except Exception:
                pass
        st.session_state["api_key"] = key

    # Sidebar
    st.sidebar.title("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï")

    if not st.session_state.get("api_key"):
        st.sidebar.warning("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key")

    page = st.sidebar.radio(
        "‡πÄ‡∏°‡∏ô‡∏π",
        ["Dashboard", "‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Statement", "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤", "‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤"],
    )

    if page == "Dashboard":
        page_dashboard()
    elif page == "‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Statement":
        page_import()
    elif page == "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤":
        page_history()
    elif page == "‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤":
        page_settings()


if __name__ == "__main__":
    main()